{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Notebook EC05**\n",
        "## Convolutional classifier for the MNIST database.\n",
        "**Professor:** Fernando J. Von Zuben <br>\n",
        "**Aluno(a):**\n"
      ],
      "metadata": {
        "id": "xMsNyA3WPrER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzk_w5ftc4bi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape to be [samples][width][height][channels]\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10)\n",
        "model.summary()\n",
        "\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "# Saving the model to disk\n",
        "model_json = model.to_json()\n",
        "json_file = open(\"model_CNN.json\", \"w\")\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "model.save_weights(\"model_CNN.h5\")\n",
        "print(\"Model saved to disk\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Behavior along the training process\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy vs Epochs')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.title('Training loss vs Epochs')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLEV4ySOdVh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the obtained results for the MNIST database (EC1 to EC5)\n",
        "classifier1 = 'Linear           '\n",
        "classifier2 = 'ELM              '\n",
        "classifier3 = 'MLP              '\n",
        "classifier4 = 'CNN              '\n",
        "print('--------------------------------------------------')\n",
        "print('|       Accuracy for the MNIST database          |')\n",
        "print('--------------------------------------------------')\n",
        "print('|Classifier type \\t Accuracy                |')\n",
        "print('--------------------------------------------------')\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier1,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier2,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier3,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier4,0.0000))\n",
        "print('--------------------------------------------------')"
      ],
      "metadata": {
        "id": "LJAt2m2TbyDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the obtained results for the CIFAR10 database (EC1 to EC5)\n",
        "classifier1 = 'Linear           '\n",
        "classifier2 = 'ELM              '\n",
        "classifier3 = 'MLP              '\n",
        "classifier4 = 'CNN              '\n",
        "print('--------------------------------------------------')\n",
        "print('|      Accuracy for the CIFAR10 database         |')\n",
        "print('--------------------------------------------------')\n",
        "print('|Classifier type \\t Accuracy                |')\n",
        "print('--------------------------------------------------')\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier1,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier2,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier3,0.0000))\n",
        "print('| %s: \\t\\t\\t%f |'% (classifier4,0.0000))\n",
        "print('--------------------------------------------------')"
      ],
      "metadata": {
        "id": "mRzCg4GRbzDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
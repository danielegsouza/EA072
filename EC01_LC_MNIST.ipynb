{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMsNyA3WPrER"
      },
      "source": [
        "## **Notebook EC01**\n",
        "## Regularized Linear Classifier for the MNIST database. Designed from scratch.\n",
        "**Professor:** Fernando J. Von Zuben <br>\n",
        "**Aluno(a):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MOfS3mVy1su0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X:  (60000, 785)\n",
            "Shape of y:  (60000,)\n",
            "Shape of Xt:  (60000, 785)\n",
            "Shape of yt:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(Xp, y), (Xtp, yt) = mnist.load_data()\n",
        "Xa = Xp.reshape(Xp.shape[0], 784)\n",
        "Xta = Xtp.reshape(Xtp.shape[0], 784)\n",
        "\n",
        "Xa = Xa / 255.0\n",
        "Xta = Xta / 255.0\n",
        "\n",
        "X0 = np.ones((Xp.shape[0],1))\n",
        "X = np.hstack((X0,Xa))\n",
        "Xt0 = np.ones((Xtp.shape[0],1))\n",
        "Xt = np.hstack((Xt0,Xta))\n",
        "\n",
        "print(\"Shape of X: \".ljust(10),  X.shape)\n",
        "print(\"Shape of y: \".ljust(10),  y.shape)\n",
        "print(\"Shape of Xt: \".ljust(10),  X.shape)\n",
        "print(\"Shape of yt: \".ljust(10),  yt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AnH2vY7Dz-pF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data point:  39418 \n",
            " Label:  9\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb CÃ©lula 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m60000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mData point: \u001b[39m\u001b[39m'\u001b[39m, ind, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLabel: \u001b[39m\u001b[39m'\u001b[39m, y[ind])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39;49mimshow(\u001b[39m255\u001b[39;49m\u001b[39m-\u001b[39;49mXp[ind], binary_string\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, width\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m fig\u001b[39m.\u001b[39mupdate_xaxes(showticklabels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielesouza/Desktop/Unicamp/EA072/ECs01a05_codes_EA072_2s2023/EC01_LC_MNIST.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m fig\u001b[39m.\u001b[39mupdate_yaxes(showticklabels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/plotly/express/_imshow.py:349\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(img, zmin, zmax, origin, labels, x, y, animation_frame, facet_col, facet_col_wrap, facet_col_spacing, facet_row_spacing, color_continuous_scale, color_continuous_midpoint, range_color, title, template, width, height, aspect, contrast_rescaling, binary_string, binary_backend, binary_compression_level, binary_format)\u001b[0m\n\u001b[1;32m    346\u001b[0m     binary_string \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m \u001b[39m+\u001b[39m slice_dimensions) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dataframe\n\u001b[1;32m    348\u001b[0m \u001b[39m# Cast bools to uint8 (also one byte)\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39;49mbool:\n\u001b[1;32m    350\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m range_color \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "# Visualizing a random data point\n",
        "import plotly.express as px\n",
        "\n",
        "ind = np.random.randint(60000)\n",
        "print('Data point: ', ind, '\\n', 'Label: ', y[ind])\n",
        "fig = px.imshow(255-Xp[ind], binary_string=True, width=200, height=200)\n",
        "fig.update_xaxes(showticklabels=False)\n",
        "fig.update_yaxes(showticklabels=False)\n",
        "fig.update_layout(margin=dict(l=1, r=1, t=1, b=1))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV-OqWPYR2ag"
      },
      "outputs": [],
      "source": [
        "# Dataset balancing analysis\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "yy = to_categorical(y)\n",
        "yyt = to_categorical(yt)\n",
        "sum_along_columns1 = np.sum(yy, axis = 0)\n",
        "print(sum_along_columns1)\n",
        "sum_along_columns2 = np.sum(yyt, axis = 0)\n",
        "print(sum_along_columns2)\n",
        "fig1 = px.bar(x=range(10),y=sum_along_columns1, width=600, height=400,\n",
        "              labels=dict(x=\"Class\", y=\"Number of examples\"), title=\"<b>Number of examples per class in the training dataset</b>\")\n",
        "fig1.update_layout(xaxis = dict(tickmode = 'linear', dtick = 1), title_x=0.5)\n",
        "fig1.show()\n",
        "fig2 = px.bar(x=range(10),y=sum_along_columns2, width=600, height=400,\n",
        "              labels=dict(x=\"Class\", y=\"Number of examples\"), title=\"<b>Number of examples per class in the test dataset</b>\")\n",
        "fig2.update_layout(xaxis = dict(tickmode = 'linear', dtick = 1), title_x=0.5)\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2_oRRd-1su3"
      },
      "outputs": [],
      "source": [
        "partition = 0.7\n",
        "\n",
        "# Mixing the dataset before partitioning\n",
        "index = np.arange(0,X.shape[0])\n",
        "np.random.shuffle(index)\n",
        "\n",
        "training_set_size = int(X.shape[0] * partition)\n",
        "\n",
        "index_training = index[:training_set_size]\n",
        "index_validation = index[training_set_size:]\n",
        "\n",
        "\n",
        "X_training = X[index_training]\n",
        "y_training = yy[index_training]\n",
        "\n",
        "X_validation = X[index_validation]\n",
        "y_validation = yy[index_validation]\n",
        "\n",
        "print(\"X_training:\".ljust(20), X_training.shape)\n",
        "print(\"y_training:\".ljust(20), y_training.shape)\n",
        "\n",
        "print(\"X_validation:\".ljust(20), X_validation.shape)\n",
        "print(\"y_validation:\".ljust(20), y_validation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NvFzhLJD4ZSW"
      },
      "outputs": [],
      "source": [
        "def get_class_from_sample(sample: np.ndarray):\n",
        "    class_ = 1\n",
        "    for i in sample:\n",
        "        if i == 0:\n",
        "            class_ += 1\n",
        "        else:\n",
        "            break\n",
        "    return class_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RT15bocK1su4"
      },
      "outputs": [],
      "source": [
        "def get_w(X, y, c):\n",
        "    w_1 = (np.matmul(np.transpose(X), X) + c * np.eye(X.shape[1]))\n",
        "    w_2 = np.matmul(np.transpose(X), y)\n",
        "    w,resid,rank,s = np.linalg.lstsq(w_1, w_2, rcond=None)\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IiMpyDst1su4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_rates_from_c_values(X, y, c_values, Ws = []):\n",
        "    hit_rates = []\n",
        "\n",
        "    if len(Ws) != 0:\n",
        "        are_Ws_given = True\n",
        "    else:\n",
        "        are_Ws_given = False\n",
        "        Ws = []\n",
        "\n",
        "    for index, c in enumerate(c_values):\n",
        "        print(c)\n",
        "\n",
        "        if are_Ws_given:\n",
        "            W = Ws[index]\n",
        "        else:\n",
        "            W = get_w(X, y, c)\n",
        "            Ws.append(W)\n",
        "\n",
        "        y_estimate = np.matmul(X,W)\n",
        "        hits = 0\n",
        "        for index, estimate in enumerate(y_estimate):\n",
        "            max_index = np.where(estimate == np.amax(estimate))[0][0]\n",
        "            estimated_class = max_index + 1\n",
        "            if estimated_class == get_class_from_sample(y[index]):\n",
        "                hits += 1\n",
        "        hit_rates.append(hits/y_estimate.shape[0])\n",
        "    return hit_rates, Ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_dbJ39H1su5"
      },
      "outputs": [],
      "source": [
        "c_values = [pow(2,d) for d in range(-10, 19, 2)] # Range goes up to 19 to ensure search up to 2^18\n",
        "\n",
        "hit_rates_training, Ws = get_rates_from_c_values(X_training, y_training, c_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y_MVJjD1su6"
      },
      "outputs": [],
      "source": [
        "hit_rates_validation, _ = get_rates_from_c_values(X_validation, y_validation, c_values, Ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puchmu481su6"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2)\n",
        "fig.set_figwidth(10)\n",
        "fig.suptitle(\"Crude search for the regularization coefficient\")\n",
        "axs[0].semilogx(c_values, hit_rates_training, 'o-')\n",
        "axs[0].set_title(\"Performance on Training set\")\n",
        "axs[0].set_ylabel(\"Hit Rate\")\n",
        "axs[0].set_xlabel(\"Regularization Coefficient 'c'\")\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].semilogx(c_values, hit_rates_validation, 'o-')\n",
        "axs[1].set_title(\"Performance on Validation set\")\n",
        "axs[1].set_ylabel(\"Hit Rate\")\n",
        "axs[1].set_xlabel(\"Regularization Coefficient 'c'\")\n",
        "axs[1].grid()\n",
        "\n",
        "best_c_index = np.where(hit_rates_validation == np.amax(hit_rates_validation))[0][0]\n",
        "\n",
        "best_c = c_values[best_c_index]\n",
        "\n",
        "print(\"Best c value: {} \\nPerformance of this value: {}\".format(best_c, hit_rates_validation[best_c_index]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONol08taaMz0"
      },
      "outputs": [],
      "source": [
        "lambd_values = c_values\n",
        "w_values = Ws\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_regularization_path(lambd_values, w_values):\n",
        "    num_coeffs = len(w_values[0])\n",
        "    for i in range(num_coeffs):\n",
        "        plt.plot(lambd_values, [wi[i] for wi in w_values])\n",
        "    plt.xlabel(r\"Regularization Coefficient 'c'\", fontsize=16)\n",
        "    plt.ylabel(r\"w_{i}\", fontsize=16)\n",
        "    plt.xscale(\"log\")\n",
        "    plt.title(\"Behavior of the weights with the degree of regularization\")\n",
        "    plt.show()\n",
        "\n",
        "plot_regularization_path(lambd_values, w_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGfLZjNO1su6"
      },
      "outputs": [],
      "source": [
        "step =  0.1 * (4 * best_c - best_c / 4);\n",
        "\n",
        "fine_c_values = np.arange((best_c/4), (4*best_c) + step / 10, step)\n",
        "\n",
        "hit_rates_training_fine, Ws_fine = get_rates_from_c_values(X_training, y_training, fine_c_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zeu_IRjh1su7"
      },
      "outputs": [],
      "source": [
        "hit_rates_validation_fine, _ = get_rates_from_c_values(X_validation, y_validation, fine_c_values, Ws_fine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmgx2-Ea1su7"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2)\n",
        "fig.set_figwidth(10)\n",
        "fig.suptitle(\"Fine search for the regularization coefficient\")\n",
        "axs[0].plot(fine_c_values, hit_rates_training_fine, 'o-')\n",
        "axs[0].set_title(\"Performance on Training set\")\n",
        "axs[0].set_ylabel(\"Hit Rate\")\n",
        "axs[0].set_xlabel(\"Regularization Coefficient 'c'\")\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].plot(fine_c_values, hit_rates_validation_fine, 'o-')\n",
        "axs[1].set_title(\"Performance on Validation set\")\n",
        "axs[1].set_ylabel(\"Hit Rate\")\n",
        "axs[1].set_xlabel(\"Regularization Coefficient 'c'\")\n",
        "axs[1].grid()\n",
        "\n",
        "best_c_index = np.where(hit_rates_validation_fine == np.amax(hit_rates_validation_fine))[0][0]\n",
        "\n",
        "best_c = fine_c_values[best_c_index]\n",
        "\n",
        "print(\"Best c value: {} \\nPerformance of this value: {}\".format(best_c, hit_rates_validation_fine[best_c_index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkzD4sCG1su8"
      },
      "outputs": [],
      "source": [
        "W = get_w(X, yy, best_c)\n",
        "print(W.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GyVL_ib1su8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "yt_estimate = np.matmul(Xt,W)\n",
        "hits = 0\n",
        "confusion_matrix = np.zeros([10, 10], dtype=int)\n",
        "for index, estimate in enumerate(yt_estimate):\n",
        "    max_index = np.where(estimate == np.amax(estimate))[0][0]\n",
        "    estimated_class = max_index + 1\n",
        "    if estimated_class == get_class_from_sample(yyt[index,:]):\n",
        "        hits += 1\n",
        "        confusion_matrix[estimated_class-1][estimated_class-1] += 1\n",
        "    else:\n",
        "        confusion_matrix[estimated_class-1][get_class_from_sample(yyt[index,:])-1] += 1\n",
        "\n",
        "print(\"Performance on test set: {}\".format(hits/yt_estimate.shape[0]))\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTAfnWbObSHk"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_df = pd.DataFrame(confusion_matrix)\n",
        "confusion_matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrM_OfMCd2X7"
      },
      "outputs": [],
      "source": [
        "FP = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "FN = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "TP = np.diag(confusion_matrix)\n",
        "TN = confusion_matrix.sum() - (FP + FN + TP)\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "# Recall, or true positive rate\n",
        "Recall = TP/(TP+FN)\n",
        "# Precision or positive predictive value\n",
        "Precision = TP/(TP+FP)\n",
        "# F1-score\n",
        "F1 =  2*(Precision * Recall)/(Precision + Recall)\n",
        "F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ly4SbfwmcAgz"
      },
      "outputs": [],
      "source": [
        "def f_score(confusion_matrix, betas):\n",
        "    recall = confusion_matrix[range(10), range(10)]/np.sum(confusion_matrix, axis=0)\n",
        "    precision = confusion_matrix[range(10), range(10)]/np.sum(confusion_matrix, axis=1)\n",
        "\n",
        "    f_scores = np.zeros((len(betas), 10))\n",
        "\n",
        "    for i, b in enumerate(betas):\n",
        "        f_scores[i] = (1 + b**2) * precision * recall/(b**2 * precision + recall)\n",
        "\n",
        "    return f_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giOVVKHJcGzj"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.plot(np.logspace(-3, 3, base=2, num=21), f_score(confusion_matrix, np.logspace(-4, 4, base=2, num=21))[:, i], label=f\"F scores for digit {i}\")\n",
        "\n",
        "ax.set_xlabel(\"$\\\\beta$\")\n",
        "ax.set_ylabel(\"score\", rotation=0, labelpad=20)\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_xticks(np.geomspace(10**-1, 10**1 ,3), [\"Towards precision\", \"1\",\"Towards recall\"], ha='right')\n",
        "ax.grid()\n",
        "box = ax.get_position()\n",
        "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "\n",
        "ax.get_xaxis\n",
        "\n",
        "# Put a legend to the right of the current axis\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "ax.set_title(\"$F_{\\\\beta}$ scores from 1/8 to 8.\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyB5LHHQNx5U"
      },
      "source": [
        "#### **Visualization of the 10 vectors of weights W, without the bias.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9i3UlkfWJeZ"
      },
      "outputs": [],
      "source": [
        "# Only for the MNIST dataset\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    weight = W[1:,i].reshape([28,28])\n",
        "    plt.title(f'Class {i}')\n",
        "    plt.imshow(weight, cmap='viridis')\n",
        "    frame1 = plt.gca()\n",
        "    frame1.axes.get_xaxis().set_visible(False)\n",
        "    frame1.axes.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "240DoJD-Nbot"
      },
      "source": [
        "#### **To improve the visualization of the 10 vectors of weights W, the use of a divergent color map is indicated: the average value of the color map is a neutral color and the extreme values represent different colors. Using a divergent color map and a bilinear interpolation scheme (to facilitate the visualization of low-resolution images), the result of the visualization of the 10 vectors of weights W is illustrated in the following images.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRozCCZrWj8_"
      },
      "outputs": [],
      "source": [
        "# Only for the MNIST dataset\n",
        "scale = np.abs(W).max()\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    weight = W[1:,i].reshape([28,28])\n",
        "    plt.title(f'Class {i}')\n",
        "    plt.imshow(weight, cmap=plt.cm.seismic, vmin=-scale/2, vmax=scale/2, interpolation='bilinear')\n",
        "    frame1 = plt.gca()\n",
        "    frame1.axes.get_xaxis().set_visible(False)\n",
        "    frame1.axes.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lGosUaXRBWs"
      },
      "source": [
        "#### **Performance of the average 10 vectors of weights (here no bias is considered)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKhRHL0uNJG_"
      },
      "outputs": [],
      "source": [
        "W1 = np.zeros((784, 10))\n",
        "for i in range(10):\n",
        "  aux = np.mean(Xp[y==i], axis=0)\n",
        "  aux = aux.reshape(784)/255\n",
        "  aux = aux-np.mean(aux)\n",
        "  W1[:,i] = aux/np.sqrt(np.sum(np.square(aux)))\n",
        "yt_estimate = np.matmul(Xta,W1)\n",
        "hits = 0\n",
        "confusion_matrix = np.zeros([10, 10], dtype=int)\n",
        "for index, estimate in enumerate(yt_estimate):\n",
        "    max_index = np.where(estimate == np.amax(estimate))[0][0]\n",
        "    estimated_class = max_index + 1\n",
        "    if estimated_class == get_class_from_sample(yyt[index,:]):\n",
        "        hits += 1\n",
        "        confusion_matrix[estimated_class-1][estimated_class-1] += 1\n",
        "    else:\n",
        "        confusion_matrix[estimated_class-1][get_class_from_sample(yyt[index,:])-1] += 1\n",
        "\n",
        "print(\"Performance on test set: {}\".format(hits/yt_estimate.shape[0]))\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBOjkqc3RmEg"
      },
      "source": [
        "#### **Visualization of the average 10 vectors of weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrG1sKXfQ31c"
      },
      "outputs": [],
      "source": [
        "# Only for the MNIST dataset\n",
        "scale = np.abs(W1).max()\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    weight = W1[:,i].reshape([28,28])\n",
        "    plt.title(f'Class {i}')\n",
        "    plt.imshow(weight, cmap=plt.cm.seismic, vmin=-scale/2, vmax=scale/2, interpolation='bilinear')\n",
        "    frame1 = plt.gca()\n",
        "    frame1.axes.get_xaxis().set_visible(False)\n",
        "    frame1.axes.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MQGRUNGKv-C"
      },
      "outputs": [],
      "source": [
        "def find_pos(item, lst):\n",
        "    pos = [i for (z, i) in zip(lst, range(len(lst))) if item == z]\n",
        "    return pos\n",
        "\n",
        "def display_sample(sample: np.ndarray):\n",
        "\n",
        "    sample = np.array(sample, dtype='float')\n",
        "    pixels = np.zeros((28,28))\n",
        "\n",
        "    for i in range(28):\n",
        "        for j in range(28):\n",
        "            pixels[i,j] = sample[i * 28 + j]\n",
        "\n",
        "    pixels = pixels.reshape((28, 28))\n",
        "    plt.imshow(pixels, cmap='viridis')\n",
        "    plt.show()\n",
        "\n",
        "yt_estimate = np.matmul(Xt,W)\n",
        "for i in range(200):\n",
        "    if yyt[i][np.argmax(yt_estimate[i,:])] != 1:\n",
        "      print(f\"Image no. {i}\")\n",
        "      display_sample(Xt[i])\n",
        "      print(f\"Real: {np.argmax(yyt[i,:])}\")\n",
        "      print(f\"Predicted: {np.argmax(yt_estimate[i,:])}\")\n",
        "      value = yt_estimate[i,np.argmax(yyt[i,:])]\n",
        "      v_sorted = np.sort(yt_estimate[i,:])\n",
        "      value_index = find_pos(value,v_sorted)\n",
        "      print(f\"Rank of the correct answer: {10 - value_index[0]}\")\n",
        "      print(f\"Probabilities: {yt_estimate[i,:]} \\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "metadata": {
      "interpreter": {
        "hash": "2fe6452616a5c56ac366cd71f0310863e24cc0ef48f8e1d866f66e4662847f82"
      }
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
